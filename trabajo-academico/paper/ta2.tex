\RequirePackage[l2tabu, orthodox]{nag}
% The following is to avoid the incompatibility between the nag package and babel.
% See https://tex.stackexchange.com/questions/240868/how-to-write-cases-with-latex
\documentclass[journal]{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage{comment}
\usepackage[english, spanish, es-lcroman]{babel}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\interdisplaylinepenalty=2500
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{array}
\usepackage[binary-units=true]{siunitx}
\usepackage{mathtools}
\usepackage{bm}

\ifCLASSOPTIONcompsoc
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfig}
\fi

\ifCLASSOPTIONcaptionsoff
\usepackage[nomarkers]{endfloat}
\let\MYoriglatexcaption\caption
\renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
\fi

\let\MYorigsubfloat\subfloat
\renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}

\usepackage{url}
\usepackage{lipsum}

\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\renewcommand{\listalgorithmname}{Lista de \ALG@name s}
\makeatother

\renewcommand\IEEEkeywordsname{Palabras clave}
\newcommand\mydots{\hbox to 1em{.\hss.\hss.}}

\renewcommand{\algorithmicend}{\textbf{fin}}
\renewcommand{\algorithmicif}{\textbf{si}}
\renewcommand{\algorithmicthen}{\textbf{luego}}
\renewcommand{\algorithmicfunction}{\textbf{función}}
\renewcommand{\algorithmicwhile}{\textbf{mientras}}
\renewcommand{\algorithmicrepeat}{\textbf{repetir}}
\renewcommand{\algorithmicdo}{\textbf{hacer}}
\renewcommand{\algorithmicfor}{\textbf{para}}

\newcommand{\Continue}{\State \textbf{continuar} }
\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%

\newcommand{\matr}[1]{\mathbf{#1}} % undergraduate algebra version
%\newcommand{\matr}[1]{#1}          % pure math version
%\newcommand{\matr}[1]{\bm{#1}}     % ISO complying version

\begin{document}
\title{Una aplicación de métricas de centralidad a redes de coautoría}
\author{Kevin~Languasco,~\IEEEmembership{20132102}
        Melany~Chávez,~\IEEEmembership{20092344}
        y~Jesús~Advíncula,~\IEEEmembership{20135452}%
}

\maketitle
\begin{abstract}
Se calculan las métricas.
\end{abstract}
\begin{IEEEkeywords}
PageRank, grafos, centralidad, coautoría
\end{IEEEkeywords}
\IEEEpeerreviewmaketitle

\section{Introducción}
\IEEEPARstart{U}{na} métrica de centralidad sobre un grafo asigna un número a cada vértice, midiendo la importancia de este. La idea intuitiva de la importancia de un vértice no está definida de manera única, por lo que se tienen diferentes métricas, cada una trabajando con un concepto diferente. \cite{brandes}.

El problema de encontrar vértices centrales tiene sus orígenes en la Sociología, donde el grafo representa una red social, y las aristas son las conexiones entre los miembros del grupo. Un nodo central se interpreta, entonces, como la persona más influyente de la red.

Las redes de coautoría son grafos donde cada nodo representa un autor, y las aristas entre dos autores tienen asignadas un peso, interpretado como la cantidad de artículos coautorados.

En este artículo, describimos tres métricas de centralidad: \textit{Closeness}, \textit{Degree} y \textit{PageRank}; y los algoritmos para calcularlos en cada caso. Como aplicación, empleamos cada algoritmo a una red de coautoría obtenida del DBLP.

\section{Descripción de métricas} \label{sec:metricas}

Definimos, como es usual, un \textbf{grafo} como un par \(G = (V, E)\), donde \(V\) es el conjunto de vértices o nodos, y \(E \subset [V]^2 \) el de aristas, con \([V]^2 = \{ X \subset V : |X| = 2 \}\). Una consecuencia de esta definición es que el grafo debe ser no dirigido y las aristas están completamente determinadas por los nodos que unen \cite{diestel}. Escribimos \(uv\) en lugar de \(\{u, v\}\) por facilidad notacional (nótese que \(uv = vu\)).

Consideramos una función \(w: E \rightarrow \mathbb{N} \) que asigna a cada arista un \textbf{peso}. Esto nos permite hablar de una relación múltiple entre dos nodos (e.g.\ múltiples colaboraciones entre dos autores)\footnote{La descripción usual para trabajar con aristas múltiples es la de multigrafo \cite{diestel}, pero preferimos emplear una función auxiliar para tener una representación más sencilla de implementar. }. 

\subsection{Degree}

Para cada vértice \(v\), sea \(\Gamma(v) = \{u \in V : uv \in E \}\) la \textbf{vecindad} de \(v\). Decimos que \(u\) es \textbf{adyacente} a \(v\) si \(u \in \Gamma(v)\). Claramente esta relación es simétrica.

Sea \(E(v) = \{uv \in E : u \in \Gamma(v) \}\). Si \(e \in E(v)\), decimos que el vértice \(v\) es \textbf{incidente} a la arista \(e\).

El \textbf{grado} de \(v\) es la cantidad de aristas incidentes con él. En nuestro caso, consideramos múltiples aristas para un par de nodos a través de la función \(w\), por lo que escribimos \cite{bollobas}

\begin{equation}
	deg(v) = \sum_{e \in E(v)} w(e)
\end{equation}

La \textbf{centralidad de grado} para un vértice es simplemente \(C_D (v) = deg(v)\).

\subsection{Closeness}

Un \textbf{camino} en un grafo es una secuencia \(p = (x_1, x_2, \dots x_n)\) de vértices tales que \(x_{i}x_{i+1} \in E\) para \(1 \leq i < n\), y su longitud es \(|p| = n\). Decimos que un camino une dos vértices \(u, v\) si \(x_1 = u\) y \(x_n = v\). Denotamos por \(P(u, v)\) al conjunto de todos los caminos que unen a \(u\) con \(v\). Sea \(c(uv) = w(uv)^{-1}\) el \textbf{costo} de la arista \(uv\). La \textbf{distancia} entre dos vértices es el resultado del siguiente problema de optimización:
\begin{equation} \label{eq:distance}
d(u, v) = \min \left(\sum_{i=1}^{n-1} c(x_{i}x_{i+1}) : (x_1, \mydots x_n) \in P(u, v)\right)
\end{equation}
Por conveniencia, definimos \(d(u, u) = 0\). Si no existe camino entre \(u\) y \(v\), i.e. \(P(u, v) = \varnothing\), se dice que \(d(u, v) = \infty\) \cite{bollobas}. La idea del costo es que, a mayor cantidad de artículos coautorados, hay más cercanía entre autores, y por ello el camino entre ellos debe ``costar menos'' \cite{newman}.

Un grafo es \textbf{conexo} si \(P(u, v) \neq \varnothing~\forall u, v \in V, u \neq v\).

La medida de \textbf{cercanía} para un nodo es \cite{brandes}:
\begin{equation} \label{eq:close}
C_C (u) = \frac{1}{\sum_{v \in V} d(u, v)}
\end{equation}

Algo que se debe tomar en cuenta es que, si no se tiene conexidad del grafo, la suma anterior no va a tener sentido. Por esto, para grafos disconexos se usa una medida parecida, definida como
\begin{equation}
C_H (u) = \sum_{v \in V \setminus \{u\}} \frac{1}{d(u, v)}
\end{equation}
Esta medida es algunas veces llamada la métrica \textbf{harmónica} de centralidad\cite{rochat}. Asumimos que \(1/\infty = 0\).

\subsection{PageRank}

Sea \(\alpha\) un número en \([0, 1]\), llamado el \textbf{factor amortiguador}.

Definimos el \textbf{PageRank} de un vértice de manera recursiva:

\begin{equation} \label{eq:pagerank}
	PR(u) = \frac{(1-\alpha)}{|V|} + \alpha \sum_{v \in \Gamma(u)} \frac{PR(v)}{deg(v)} w(uv)
\end{equation}

Llamaremos a cada término de la sumatoria el \textit{aporte del vértice} \(v\) \textit{al vértice} \(u\).

PageRank fue originalmente diseñado para cuantificar la importancia de un sitio web, con el fin de implementar un sistema de búsqueda. La definición se basa en la idea de una persona a la que se le asigna un sitio web aleatorio, y va moviéndose a otros sitios a través de hipervínculos. El factor amortiguador es la probabilidad de que la persona deje de hacer este procedimiento y pida otro sitio aleatorio. El PageRank de un sitio web representa la probabilidad de que la persona ingrese al mismo \cite{google}. El aporte a cada sitio a donde se apunta se distribuye equitativamente.

La definición original se aplica a grafos dirigidos sin aristas múltiples. En nuestro caso, no hace falta distinguir entre hipervínculos que salen del sitio web, y los que van hacia él. Sin embargo, sí es importante tomar en cuenta los pesos asignados a cada arista. Si un autor colabora más de una vez con una persona importante, esto debe reflejarse en el PageRank asignado. Por eso, el aporte ya no es equitativo entre los vecinos de un nodo, pero sí entre sus aristas. Para considerar este efecto, se pone el factor del peso en el aporte.

El factor de amortiguamiento es importante para grafos disconexos, pues tomando \(\alpha = 1\), si se empieza en un vértice cualquiera, la probabilidad de llegar a los de una componente conexa diferente va a ser nula. Por otro lado, si \(\alpha = 0\), el viaje será completamente aleatorio. La calibración de este parámetro influenciará, entonces, en qué medida la estructura propia del grafo influenciará en la asignación de importancia. En la literatura original se trabajó con \(\alpha = 0.85\) \cite{google}, y este es el valor que consideraremos para los experimentos.

\section{Algoritmos}

La métrica del grado se calcula de manera directa: Para cada nodo, sumamos los pesos de todas las aristas incidentes a él.

La medida de cercanía involucra resolver el problema de minimización planteado en la Ecuación \ref{eq:distance}. Este es un problema conocido, y se puede resolver de varias formas.

Ya que se necesita calcular el camino más corto entre todo par de nodos en el grafo, se puede aplicar el algoritmo de Floyd-Warshall, con complejidad \(\Theta(|V|^3)\) \cite{clrs}. Sin embargo, si el grafo es esparso\footnote{Se considera esparso cuando \(|E| = o(|V|^2 / \log(|V|))\)\cite{clrs}}, se puede considerar aplicar el algoritmo de Dijkstra para todo vértice, con complejidad \(\mathcal{O}(|V||E|\ln |V|)\) usando colas de prioridad. Esta alternativa es la que se usó en la presente investigación, al ser relativamente de baja complejidad y más eficiente para el caso particular de interés.

La función \textproc{Dijkstra} usa un arreglo de distancias mínimas, donde todas están inicializadas a \(\infty\), con excepción del nodo raíz, que tiene distancia \(0\) hacia sí mismo. La cola de prioridad usada \(P\) está compuesta por 2-tuplas \((d, u)\), donde \(d\) es la distancia desde el nodo raíz hasta \(u\). Cada vez que saquemos el nodo con mínima distancia \(u\) de \(P\), se compara, para cada vértice adyacente \(v\), la distancia si se sigue por \(u\) hasta \(v\), y la hipotética distancia mínima actual para \(v\). Si la distancia efectivamente disminuye, actualizamos el arreglo de distancias mínimas. En este punto, una técnica usual es disminuir la prioridad de \(v\) en \(P\)\cite{heap}, pero esto implicaría reordenar la estructura. Optamos por agregar \((nuevo, v)\) a \(P\), donde \(nuevo\) es la nueva distancia mínima hallada. Nótese entonces que cada nodo \(u\) puede aparecer más de una vez, pero en este caso sólo sale de la cola, sin hacer más computación. Para hallar la métrica de cercanía, se aplica la Ecuación \ref{eq:close} sobre el arreglo \(dist\) resultante.
\begin{algorithm}[H]
	\caption{Algoritmo de Dijkstra} \label{alg:dijkstra}
\begin{algorithmic}
	\Function{Dijkstra}{$Grafo$, $fuente$}
		\State $dist[fuente] \gets 0$
		\State $P.agregar((0, fuente))$
		\For{$u \in Grafo, u \neq fuente$}
			\State $dist[u] = \infty$
		\EndFor
		\While {$P$ no está vacío}
			\State $(d, u) \gets P.sacar\_min()$
			\If{$d <= dist[u]$}
				\For{$uv \in E(u)$}
					\State $peso \gets 1/w(uv)$
					\State $nuevo \gets peso + dist[u]$
					\If{$nuevo < dist[v]$}
						\State $dist[v] = nuevo$
						\State $P.agregar((nuevo, v))$
					\EndIf
				\EndFor	
			\EndIf
		\EndWhile
	\EndFunction
\end{algorithmic}
\end{algorithm}
PageRank puede ser interpretado de la siguiente manera. Consideremos la matriz \(\matr{H} = [H_{ij}]\) dada por:
\begin{equation}
	H_{ij} =
	\begin{dcases}
	\frac{w(v_i v_j)}{deg(v_j)} &\text{si $v_i v_j \in E$}\\
	0\phantom{\frac{1}{|V|}} &\text{caso contrario}
	\end{dcases}
\end{equation}
Esta matriz tiene la propiedad de que la suma de sus columnas es \(1\), y ninguna entrada es negativa. En la literatura, una matriz con esta propiedad es llamada \textbf{matriz estocástica izquierda}. En los trabajos originales sobre PageRank, era de interés calcular la importancia de sitios web sin hipervínculos, en cuyo caso la matriz anterior requiere de una pequeña modificación \cite{google}. En nuestro caso, esto no es necesario ya que en las redes de coautoría sólo se trabajan con autores que han publicado conjuntamente con otros autores, haciendo que no puedan existir vértices aislados.

Cada entrada se interpreta como la probabilidad de llegar al vértice \(v_i\) inmediatamente a partir del \(v_j\). Como ya se mencionó en el Capítulo \ref{sec:metricas}, es importante que se tome un valor razonable de \(\alpha\). Con este fin, introducimos una nueva matriz \(\matr{J}\) tal que todas sus entradas son la unidad.

La \textbf{matriz de Google} será \cite{langville}
\begin{equation}
	\matr{G} = \frac{1-\alpha}{|V|} \matr{J} + \alpha \matr{H}
\end{equation}
Por convexidad, \(\matr{G}\) también es estocástica izquierda. El problema de resolver la Ecuación \ref{eq:pagerank} simultáneamente para todos los vértices es equivalente a encontrar algún \(\bm{\pi} \in \mathbf{R}^{|V|} \) tal que
\begin{equation}
	\matr{G} \bm{\pi} = \bm{\pi}
\end{equation}
En otras palabras, nos interesa encontrar un eigenvector asociado al eigenvalor \(\lambda = 1\). Es un resultado conocido que este eigenvector existe y es único, y que \(1\) es el máximo valor absoluto posible para eigenvalores de matrices estocásticas\cite{meyer}.

El método para resolver este problema, conocido como el \textbf{método de potencias}, consiste en aplicaciones iteradas de la matriz \(\matr{G}\) a un vector \(\bm{\pi}_0\) inicial. La demostración de convergencia consiste en descomponer \(\matr{G}\) en bloques de Jordan y aplicar el resultado mencionado en el párrafo anterior\cite{langville}.

La elección del vector inicial \(\bm{\pi}_0\) influye en la velocidad de convergencia del algoritmo. Es usual tomar \(\bm{\pi}_0 = \frac{1}{|V|} \bm{1} \), donde \(\bm{1}\) tiene cada componente igual a \(1\). Otra alternativa es inicializar el vector con los valores de las dos métricas anteriores, esperando que se esté más cerca al eigenvector deseado.

\begin{algorithm}[H]
	\caption{PageRank} \label{alg:pagerank}
	\begin{algorithmic}
		\Function{PageRank}{$Grafo$, $\epsilon$, $\alpha$}
			\State Inicializar los vértices
			\Do
				\State $\Delta \gets 0$
				\For{$u \in Grafo$}
					\State $PR_0 \gets PR(u)$
					\State $PR_1 \gets 0$
					\For{$uv \in E(u)$}
						\State $PR_1 \gets PR_1 + (PR(v) \times w(uv))/deg(v)$
					\EndFor
					\State $PR_1 \gets PR_1 \times \alpha$
					\State $PR_1 \gets PR_1 + (1-\alpha)/|V|$
					\State $PR(u) \gets PR_1$
					\State $\Delta \gets max(\Delta, |PR_1 - PR_0|)$
				\EndFor
			\doWhile{$\Delta > \epsilon$}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\section{Experimentos y resultados}
El grafo resultante contiene un total de \num{1411345} vértices y \num{5946615} aristas, sin contar sus pesos (contándolos, hay \num{10615809}). Este grafo es lo suficientemente esparso para considerar el uso de colas de prioridad.

Para los siguientes experimentos, se ha usado una computadora con procesador Intel i7-3770k, \SI{16}{\giga\byte} de memoria RAM y Windows 10. Todas las estructuras de datos y los algoritmos fueron implementados en C. El compilador usado fue Visual C++.

Hay una diferencia bastante pronunciada entre los tiempos de cálculo de las métricas de grado y PageRank, y la de cercanía, como se puede observar en el Cuadro \ref{tejecucion}.

\begin{table}
	\renewcommand{\arraystretch}{1.3}
	\caption{Tiempos de ejecución}
	\label{tejecucion}
	\centering
	\begin{tabular}{c|c|c|c}
		\hline
		Experimento & \(C_D\) & \(C_C\) & \(C_{PR}\) (it.) \\
		\hline\hline
		1 & 2.0 & 3 & 4 (5) \\
		2 & 2.0 & 3 & 4 (4) \\
		3 & 2.0 & 3 & 4 (3) \\
		\hline
	\end{tabular}
\end{table}


\section{Discusión}

\section{Conclusiones}

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\IEEEtriggeratref{8}


\begin{thebibliography}{2}

\bibitem{brandes}
U.~Brandes \textit{et al.}, \emph{Network Analysis: Methodological Foundations}.\hskip 1em plus
0.5em minus 0.4em\relax Saarland, Alemania: Springer, 2005, pp. 16-34.

\bibitem{bondy}
J.~Bondy y U.~Murty, \emph{Graph Theory}. Londres, Inglaterra: Springer, 2008.

\bibitem{diestel}
R.~Diestel, \emph{Graph Theory}, 3ra edición. Heidelberg, Alemania: Springer, 2005.

\bibitem{bollobas}
B.~Bollobás, \emph{Modern Graph Theory}. New York City, NY: Springer, 1998.

\bibitem{google}
S.~Brin y L.~Page, ``The Anatomy of a Large-Scale Hypertextual Web Search Engine''. \emph{Computer Networks and ISDN Systems}, vol. 30, pp. 107–117, Abril 1998.

\bibitem{langville}
A.~Langville, C.~Meyer, \emph{Google's PageRank and Beyond: The Science of Search Engine Rankings}. Princeton, NJ: Princeton University Press, 2012.

\bibitem{newman}
M.~Newman, ``Scientific collaboration networks. II\@. Shortest paths, weighted networks, and centrality''. \emph{Physical Review}, vol. 64, Junio 2001.

\bibitem{sinha}
R.~Sinha y R.~Mihalcea, ``Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity'' en \emph{Proceedings of the International Conference on Semantic Computing}, Washington, DC, 2007, pp. 363-369.

\bibitem{heap}
M.~Chen \textit{et al.}, ``Priority Queues and Dijkstra’s Algorithm,'' The University of Texas at Austin, Department of Computer Sciences, Austin, TX, Rep. TR-07-54, Oct. 2007.

\bibitem{clrs}
T.~Cormen \textit{et al.} \emph{Introduction to Algorithms}. Cambridge, MA: MIT Press, 2009.

\bibitem{rochat}
Y.~Yannick, ``Closeness Centrality Extended To Unconnected Graphs: The Harmonic Centrality Index,'' University of Lausanne, Institute of Applied Mathematics, Suiza, 2009.

\bibitem{meyer}
C.~Meyer. \emph{Matrix analysis and applied linear algebra}. Philadelphia, PA: Society for Industrial and Applied Mathematics
, 2000.

\end{thebibliography}

\end{document}

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.

